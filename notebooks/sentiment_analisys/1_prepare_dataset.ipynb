{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982b7d8b-395e-4553-975a-f04e76295fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2f64ab-11a0-4d49-98c9-cd26183396da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'../../src')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import util as ut \n",
    "import shutil\n",
    "import dataset as ds\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608b483-bf61-4f4f-8e8c-4f5a3d588563",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62473dc8-7166-4729-94b0-dc91964e4d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sets_counts(path):\n",
    "    train_pos_size = len(glob.glob(f'{path}/dataset/train/pos/*.txt'))\n",
    "    eval_pos_size  = len(glob.glob(f'{path}/dataset/eval/pos/*.txt'))\n",
    "    test_pos_size  = len(glob.glob(f'{path}/dataset/test/pos/*.txt'))\n",
    "    \n",
    "    train_neg_size = len(glob.glob(f'{path}/dataset/train/neg/*.txt'))\n",
    "    eval_neg_size  = len(glob.glob(f'{path}/dataset/eval/neg/*.txt'))\n",
    "    test_neg_size  = len(glob.glob(f'{path}/dataset/test/neg/*.txt'))\n",
    "\n",
    "    all_pos_size   = train_pos_size + eval_pos_size + test_pos_size\n",
    "    all_neg_size   = train_neg_size + eval_neg_size + test_neg_size\n",
    "\n",
    "    print(f'All: {(all_pos_size, all_neg_size)}, Train: {(train_pos_size, train_neg_size)}, Eval: {(eval_pos_size, eval_neg_size)}, Test: {(test_pos_size, test_neg_size)}')\n",
    "\n",
    "    return (train_pos_size, eval_pos_size, test_pos_size)\n",
    "\n",
    "\n",
    "\n",
    "def download_dataset(\n",
    "    path          = '../../',\n",
    "    train_percent = 0.7, \n",
    "    eval_percent  = 0.2, \n",
    "    test_percent  = 0.1\n",
    "):\n",
    "    if os.path.exists(f'{path}/dataset'):\n",
    "        return sets_counts(path)\n",
    "\n",
    "    !rm -rf {path}/aclImdb\n",
    "    !rm -rf {path}/aclImdb_v1.tar.gz\n",
    "\n",
    "    !cd {path}; wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "    !cd {path}; tar -xf aclImdb_v1.tar.gz\n",
    "    \n",
    "    !cd {path}; rm aclImdb_v1.tar.gz\n",
    "        \n",
    "    !cd {path}; mv aclImdb dataset\n",
    "    \n",
    "    !cd {path}/dataset; mv train all\n",
    "    !cd {path}/dataset; mv test/pos/* all/pos/\n",
    "    !cd {path}/dataset; mv test/neg/* all/neg/\n",
    "    !cd {path}/dataset; rm -rf test\n",
    "\n",
    "    pos_files = glob.glob(f'{path}/dataset/all/pos/*.txt')\n",
    "    neg_files = glob.glob(f'{path}/dataset/all/neg/*.txt')\n",
    "  \n",
    "    random.shuffle(pos_files)\n",
    "    random.shuffle(neg_files)\n",
    "\n",
    "    ut.mkdir(f'{path}/dataset/train/pos')\n",
    "    ut.mkdir(f'{path}/dataset/train/neg')\n",
    "    \n",
    "    ut.mkdir(f'{path}/dataset/eval/pos')\n",
    "    ut.mkdir(f'{path}/dataset/eval/neg')\n",
    "    \n",
    "    ut.mkdir(f'{path}/dataset/test/pos')\n",
    "    ut.mkdir(f'{path}/dataset/test/neg')\n",
    " \n",
    "    train_size = int(len(pos_files) * train_percent)\n",
    "    eval_size  = int(len(pos_files) * eval_percent)\n",
    "    test_size  = int(len(pos_files) * test_percent)\n",
    "\n",
    "    for f in pos_files[:train_size]: shutil.copy(f,  f'{path}/dataset/train/pos')\n",
    "    for f in neg_files[:train_size]: shutil.copy(f,  f'{path}/dataset/train/neg')\n",
    "\n",
    "    for f in pos_files[train_size:train_size+eval_size]: shutil.copy(f,  f'{path}/dataset/eval/pos')\n",
    "    for f in neg_files[train_size:train_size+eval_size]: shutil.copy(f,  f'{path}/dataset/eval/neg')\n",
    "\n",
    "    for f in pos_files[train_size+eval_size:train_size+eval_size+test_size]: shutil.copy(f,  f'{path}/dataset/test/pos')\n",
    "    for f in neg_files[train_size+eval_size:train_size+eval_size+test_size]: shutil.copy(f,  f'{path}/dataset/test/neg')\n",
    "    \n",
    "    !cd {path}/dataset; rm -rf all\n",
    "\n",
    "    return sets_counts(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ae5ae-b8ea-4b8c-b2e2-a9b1307dd111",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82fc1010-8e07-45f1-94fd-c87363fff1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">All: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2359</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2359</span><span style=\"font-weight: bold\">)</span>, Train: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1502</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1502</span><span style=\"font-weight: bold\">)</span>, Eval: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">)</span>, Test: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">214</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">214</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "All: \u001b[1m(\u001b[0m\u001b[1;36m2359\u001b[0m, \u001b[1;36m2359\u001b[0m\u001b[1m)\u001b[0m, Train: \u001b[1m(\u001b[0m\u001b[1;36m1502\u001b[0m, \u001b[1;36m1502\u001b[0m\u001b[1m)\u001b[0m, Eval: \u001b[1m(\u001b[0m\u001b[1;36m643\u001b[0m, \u001b[1;36m643\u001b[0m\u001b[1m)\u001b[0m, Test: \u001b[1m(\u001b[0m\u001b[1;36m214\u001b[0m, \u001b[1;36m214\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m1502\u001b[0m, \u001b[1;36m643\u001b[0m, \u001b[1;36m214\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_dataset(\n",
    "    train_percent = 0.07, \n",
    "    eval_percent  = 0.03, \n",
    "    test_percent  = 0.01\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
